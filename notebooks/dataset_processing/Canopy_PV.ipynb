{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3920551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path_to_this_notebook = os.path.abspath('.')\n",
    "path_to_project = path_to_this_notebook[:path_to_this_notebook.find('note')]\n",
    "sys.path.append(path_to_project)\n",
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d04ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvPDC_kW_Avg</th>\n",
       "      <th>InvPAC_kW_Avg</th>\n",
       "      <th>PwrMtrP_kW_Avg</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InvPDC_kW_Avg  InvPAC_kW_Avg  PwrMtrP_kW_Avg        date   time\n",
       "0            0.0            0.0             0.0  2015-01-01  00:00\n",
       "1            0.0            0.0             0.0  2015-01-01  00:01\n",
       "2            0.0            0.0             0.0  2015-01-01  00:02\n",
       "3            0.0            0.0             0.0  2015-01-01  00:03\n",
       "4            0.0            0.0             0.0  2015-01-01  00:04"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "full_df = pd.DataFrame()\n",
    "columns_to_take = ['TIMESTAMP', 'InvPDC_kW_Avg', 'InvPAC_kW_Avg', 'PwrMtrP_kW_Avg']\n",
    "p_cols = ['InvPDC_kW_Avg', 'InvPAC_kW_Avg', 'PwrMtrP_kW_Avg']\n",
    "path_to_data = path_to_project + '/data/pvdata.nist.gov/'\n",
    "for year in ['2015', '2016', '2017']:\n",
    "    for month in sorted(os.listdir(path_to_data + year + '/')):\n",
    "        for day in sorted(os.listdir(path_to_data + year + '/' + month + '/')):\n",
    "            path = path_to_data + year + '/' + month + '/' + day\n",
    "            df = pd.read_csv(path)[columns_to_take]\n",
    "            full_df = pd.concat([full_df, df])\n",
    "# Create date and time columns         \n",
    "date = full_df['TIMESTAMP'].apply(lambda x: x[:10])\n",
    "time = full_df['TIMESTAMP'].apply(lambda x: x[11:16])\n",
    "full_df['date'] = date\n",
    "full_df['time'] = time\n",
    "full_df = full_df.drop(['TIMESTAMP'], axis=1)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c4c2afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10309 0.006531959651257096\n"
     ]
    }
   ],
   "source": [
    "group_th = 60\n",
    "\n",
    "# Determine bad indices which have either nan or large negative value\n",
    "df_processed = full_df.copy()\n",
    "for c in p_cols:\n",
    "    df_processed[c] = full_df[c].apply(lambda x: max(0, x) if x >= -1 else np.nan)\n",
    "df_processed = df_processed.reset_index(drop=True)\n",
    "\n",
    "inds_na1 = np.where(df_processed['InvPDC_kW_Avg'].isna())[0]\n",
    "inds_na2 = np.where(df_processed['InvPAC_kW_Avg'].isna())[0]\n",
    "inds_na3 = np.where(df_processed['PwrMtrP_kW_Avg'].isna())[0]\n",
    "bad_inds = set(inds_na1) | set(inds_na2) | set(inds_na3)\n",
    "bad_inds = sorted(list(bad_inds))\n",
    "print(len(bad_inds), len(bad_inds) / len(df_processed))\n",
    "\n",
    "# Group indexes such that group is [i, i+1, i+2, i+g]\n",
    "bad_groups_raw = []\n",
    "prev_i = None\n",
    "current_group = []\n",
    "\n",
    "for i in bad_inds:\n",
    "    if len(current_group) == 0:\n",
    "        current_group.append(i)\n",
    "    else:\n",
    "        if i - 1 == current_group[-1] and df_processed['date'].iloc[i] ==  df_processed['date'].iloc[i - 1]:\n",
    "            current_group.append(i)\n",
    "        else:\n",
    "            bad_groups_raw.append(list(current_group))\n",
    "            current_group = [i]\n",
    "            \n",
    "if len(current_group):\n",
    "    bad_groups_raw.append(list(current_group))\n",
    "    \n",
    "# For groups of nan smaller than group_th, we simply interpolate them. We use large value of group_th, \n",
    "# but it's fine since ther are not that many large groups. We also add multiplicative noise during interpolation\n",
    "bad_groups = [] \n",
    "for group in bad_groups_raw:\n",
    "    if len(group) > group_th:\n",
    "        bad_groups.append(list(group))\n",
    "    else:\n",
    "        for c in p_cols:\n",
    "            val_start = df_processed.iloc[group[0] -1][c]\n",
    "            val_end = df_processed.iloc[group[-1] + 1][c]\n",
    "            new_group_vals = np.linspace(val_start, val_end, len(group) + 2)[1: -1]\n",
    "            for i, val in zip(group, new_group_vals * np.random.normal(1, 0.05, size=len(group))):\n",
    "                df_processed.loc[i, c] = val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3004ee10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9132, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update bad inds \n",
    "bad_inds = set()\n",
    "for gr in bad_groups:\n",
    "    for i in gr:\n",
    "        bad_inds.add(i)\n",
    "bad_inds = list(bad_inds)\n",
    "len(bad_inds), len(bad_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca567ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute what dates still have nans\n",
    "dates_to_na = defaultdict(lambda: 0)\n",
    "dates_to_na_inds = defaultdict(list)\n",
    "for i in bad_inds:\n",
    "    date = df_processed['date'].iloc[i]\n",
    "    dates_to_na[date] += 1\n",
    "    dates_to_na_inds[date].append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409a774b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(<function __main__.<lambda>()>,\n",
       "             {'2017-10-21': 1440,\n",
       "              '2017-10-22': 1440,\n",
       "              '2017-10-23': 753,\n",
       "              '2015-06-14': 488,\n",
       "              '2015-06-15': 438,\n",
       "              '2017-06-15': 81,\n",
       "              '2017-06-02': 1025,\n",
       "              '2017-06-03': 1440,\n",
       "              '2017-06-04': 1018,\n",
       "              '2017-10-20': 1009}),\n",
       " 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_to_na, len(dates_to_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27ab5ebb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Simply drop all dates with nans\n",
    "dates_to_drop = dates_to_na.keys()\n",
    "mask = ~df_processed['date'].isin(dates_to_drop)\n",
    "df_processed = df_processed[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad65092",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict ={'solar_rated_power': 243, }\n",
    "dates = df_processed['date'].unique()\n",
    "metadata_dict['dates'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f32042",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_data + 'metadata_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(metadata_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f629270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "df_processed.to_csv(path_to_data + 'processed_data.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d7053eaf1f44e4ba09689f8d46ffe60bb595916505f14727b0e14a5d0bba04d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
